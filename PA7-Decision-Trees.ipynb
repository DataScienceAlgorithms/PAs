{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CPSC 322]() Data Science Algorithms\n",
    "[Gonzaga University](https://www.gonzaga.edu/) |\n",
    "[Sophina Luitel](https://www.gonzaga.edu/school-of-engineering-applied-science/faculty/detail/sophina-luitel-phd-0dba6a9d)\n",
    "\n",
    "---\n",
    "\n",
    "# PA7 Decision Trees (100 pts)\n",
    "\n",
    "## Learner Objectives\n",
    "At the conclusion of this programming assignment, participants should be able to:\n",
    "* Represent a tree in Python\n",
    "* Implement a decision tree classifier using the TDIDT algorithm\n",
    "* Select an attribute using entropy\n",
    "* Extract rules from a decision tree\n",
    "* Consider the effects of using different feature subsets\n",
    "* (BONUS) Visualize a tree with Graphviz and DOT\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "Before starting this programming assignment, participants should be able to:\n",
    "* Implement test-driven development\n",
    "* Evaluate classifiers using train/test sets\n",
    "* Understand tree representations and common tree traversal algorithms\n",
    "* Understand recursion\n",
    "* Tell a data science story using Jupyter Notebook\n",
    "* Understand Bramer Chapters 4 (Using Decision Trees for Classification), 5 (Decision Tree Induction), and Chapter 9 (Avoiding Overfitting of Decision Trees)\n",
    "\n",
    "## Acknowledgments\n",
    "Content used in this assignment is based upon information in the following sources:\n",
    "* Adapted from Dr. Gina Sprint's, Data Science Algorithms, Fall 2024\n",
    "* [Mushroom Dataset](https://archive.ics.uci.edu/dataset/73/mushroom), UCI Machine Learning Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github Classroom Setup\n",
    "For this assignment, you will use GitHub Classroom to create a private code repository to track code changes and submit your assignment. Open this PA7 link to accept the assignment and create a private repository for your assignment in Github classroom: https://classroom.github.com/a/crrsupbJ\n",
    "\n",
    "Your repo, for example, will be named DataScienceAlgorithms/pa7-yourusername (where yourusername is your Github username). I highly recommend committing/pushing regularly so your work is always backed up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview and Requirements\n",
    "This assignment involves implementing a decision tree classifier. It has two main parts:\n",
    "1. `mysklearn`: Test and implement a general and re-usable decision tree classifier\n",
    "1. Mushroom edibility classification (pa7.ipynb): Write a Jupyter Notebook that uses `mysklearn` to perform classification tasks on a mushroom dataset\n",
    "\n",
    "I highly encourage you to design functions that are generic and re-usable for future programming assignments and data mining tasks.\n",
    "\n",
    "Note: we are learning data science from scratch! The only non-standard Python libraries you should need to use for this assignment are `tabulate`, `numpy` (math functions, random number generation, etc.), and `scipy` (sparingly). This means that beyond these libraries, you should not `pip install` any additional libraries beyond what is included in the [continuumio/anaconda3:2024.06-1](https://hub.docker.com/r/continuumio/anaconda3) Docker image and you should not use `pandas/sklearn/`etc... (exceptions are made for testing purposes only!!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: `mysklearn` (65 pts)\n",
    "Our decision tree classifier we are going to implement will:\n",
    "* Be constructed/stored using the nested list representation described in class\n",
    "* Use the entropy-based attribute selection method described in class\n",
    "* Use the majority voting method to deal with clashes described in class\n",
    "* Only work with categorical attributes (you will not need to use any continuous attributes with your decision tree classifier in this assignment)\n",
    "\n",
    "### Step 1: Implement Decision Tree Unit Tests for `myclassifiers.py`\n",
    "Finish the decision tree unit tests in `test_myclassifiers.py` for `MyDecisionTreeClassifier` (Class API design inspiration: Sci-kit Learn's [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html))\n",
    "1. `fit(X_train, y_train)`\n",
    "    1. Finish the test function `test_decision_tree_classifier_fit()` by implementing the following test cases\n",
    "        1. Use the 14 instance \"interview\" training set example traced in class, asserting against the tree constructed in [B Attribute Selection (Entropy) Lab Task #1](https://github.com/DataScienceAlgorithms/M5_DecisionTrees/blob/main/B%20Attribute%20Selection.ipynb)\n",
    "        1. Use the 15 instance \"iPhone\" training set example from LA7, asserting against the tree you create with a desk check\n",
    "            * Note: this dataset has clashes in it and when resolving the clashes you will have ties with majority voting... in this case, choose the class label that comes alphabetically first in the attribute domain, that way we all have the same solution tree (as opposed to using a random number generator and flipping a coin, which introduces complexity related to seeding and consistency across solutions)\n",
    "1. `predict(X_test)`\n",
    "    1. Finish the test function `test_decision_tree_classifier_predict()` by implementing the following test cases\n",
    "        1. Use the 14 instance \"interview\" training set example traced in class, asserting against the two predictions made in [B Attribute Selection (Entropy) Lab Task #2](https://github.com/DataScienceAlgorithms/M5_DecisionTrees/blob/main/B%20Attribute%20Selection.ipynb)\n",
    "        1. For the 15 instance \"iPhone\" training set example from LA7, use the same two unseen instances from LA7, asserting against the solution predictions from your own desk check\n",
    "        \n",
    "For convenience, I've provided the \"interview\" dataset as Python lists below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interview dataset\n",
    "header_interview = [\"level\", \"lang\", \"tweets\", \"phd\", \"interviewed_well\"]\n",
    "X_train_interview = [\n",
    "    [\"Senior\", \"Java\", \"no\", \"no\"],\n",
    "    [\"Senior\", \"Java\", \"no\", \"yes\"],\n",
    "    [\"Mid\", \"Python\", \"no\", \"no\"],\n",
    "    [\"Junior\", \"Python\", \"no\", \"no\"],\n",
    "    [\"Junior\", \"R\", \"yes\", \"no\"],\n",
    "    [\"Junior\", \"R\", \"yes\", \"yes\"],\n",
    "    [\"Mid\", \"R\", \"yes\", \"yes\"],\n",
    "    [\"Senior\", \"Python\", \"no\", \"no\"],\n",
    "    [\"Senior\", \"R\", \"yes\", \"no\"],\n",
    "    [\"Junior\", \"Python\", \"yes\", \"no\"],\n",
    "    [\"Senior\", \"Python\", \"yes\", \"yes\"],\n",
    "    [\"Mid\", \"Python\", \"no\", \"yes\"],\n",
    "    [\"Mid\", \"Java\", \"yes\", \"no\"],\n",
    "    [\"Junior\", \"Python\", \"no\", \"yes\"]\n",
    "]\n",
    "y_train_interview = [\"False\", \"False\", \"True\", \"True\", \"True\", \"False\", \"True\", \"False\", \"True\", \"True\", \"True\", \"True\", \"True\", \"False\"]\n",
    "\n",
    "# note: this tree uses the generic \"att#\" attribute labels because fit() does not and should not accept attribute names\n",
    "# note: the attribute values are sorted alphabetically\n",
    "tree_interview = \\\n",
    "        [\"Attribute\", \"att0\",\n",
    "            [\"Value\", \"Junior\", \n",
    "                [\"Attribute\", \"att3\",\n",
    "                    [\"Value\", \"no\", \n",
    "                        [\"Leaf\", \"True\", 3, 5]\n",
    "                    ],\n",
    "                    [\"Value\", \"yes\", \n",
    "                        [\"Leaf\", \"False\", 2, 5]\n",
    "                    ]\n",
    "                ]\n",
    "            ],\n",
    "            [\"Value\", \"Mid\",\n",
    "                [\"Leaf\", \"True\", 4, 14]\n",
    "            ],\n",
    "            [\"Value\", \"Senior\",\n",
    "                [\"Attribute\", \"att2\",\n",
    "                    [\"Value\", \"no\",\n",
    "                        [\"Leaf\", \"False\", 3, 5]\n",
    "                    ],\n",
    "                    [\"Value\", \"yes\",\n",
    "                        [\"Leaf\", \"True\", 2, 5]\n",
    "                    ]\n",
    "                ]\n",
    "            ]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: `fit()` and `predict()`\n",
    "Complete the `mysklearn.myclassifiers.MyDecisionTreeClassifier` methods `fit()` and `predict()` and test your code for functional correctness against the above unit tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: `print_decision_rules()`\n",
    "Finish the `print_decision_rules()` method of `MyDecisionTreeClassifier` that prints out the rules inferred from a decision tree created from a call to `fit()`. Your rules should take the form:\n",
    "\n",
    "```\n",
    "IF att0 == val AND ... THEN class = label\n",
    "IF att1 == val AND ... THEN class = label\n",
    "...\n",
    "```\n",
    "\n",
    "Where \"att0\", \"att1\", ... and \"class\" are replaced with the contextual attribute names and class name if the keyword argument `attribute_names` is not None."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Mushroom Classification (25 pts)\n",
    "\n",
    "Create a decision tree classifier for a Mushroom dataset. I extracted the dataset from here: https://archive.ics.uci.edu/dataset/73/mushroom. The dataset has been reduced to 500 instances for simplicity and only includes a subset of 9 predictive features, with each feature’s values simplified to at most 3 categories.\n",
    "\n",
    "Some notes:\n",
    "* The dataset has been sampled and slightly modified from the original to make it suitable for this assignment.\n",
    "* Each feature is categorical and has been simplified for easier interpretation.\n",
    "* The target class is `label`, which indicates whether a mushroom is edible or poisonous.\n",
    "\n",
    "The features in this dataset are:\n",
    "* cap-color: gray, brown, other\n",
    "* odor: foul, none, other\n",
    "* stalk-surface-above-ring: smooth, silky, other\n",
    "* stalk-surface-below-ring: smooth, silky, other\n",
    "* stalk-color-above-ring: pink, white, other\n",
    "* stalk-color-below-ring: pink, white, other\n",
    "* ring-type: pendant, evanescent, other\n",
    "* population: several, other\n",
    "* habitat: wood, grass, other\n",
    "\n",
    "The target class (to predict) is:\n",
    "label:  edible or poisonous\n",
    "\n",
    "Since each feature is categorical, you do not need to perform any discretization, etc. The following two steps below have you exploring different subsets. For each step, create decision tree classifier to predict the label of mushroom. Test your classifier using k-fold cross-validation (with k = 10, use stratified k-fold cross validation if you implemented it for the PA5 bonus). Format your results as per PA6 and compare your results using:\n",
    "1. Accuracy and error rate\n",
    "1. Precision, recall, and F1 measure\n",
    "1. Confusion matrices\n",
    "   \n",
    "### Step 1: Using only the Odor Feature\n",
    "\n",
    "This provides a baseline set of results. It shows how accurately the model can predict whether a mushroom is edible or poisonous when using only the odor feature.\n",
    "\n",
    "### Step 2: Try 3–4 small feature subsets (2–5 features each). \n",
    "\n",
    "Example subsets:  \n",
    "Subset 1: odor, cap-color  \n",
    "Subset 2: odor, stalk-surface-above, stalk-color-above  \n",
    "Subset 3: odor, ring-type, spore-print-color  \n",
    "Subset 4: odor, cap-color, stalk-color-below, population, habitat  \n",
    "\n",
    "Run 10-fold CV for each subset and compare performance. Identify the subset that gives the best predictive performance.  \n",
    "\n",
    "Notes:\n",
    "1. You do not need to try all possible combinations, just pick some subsets.\n",
    "2. Because decision trees tend to overfit, start with only 2–5 features; otherwise, your decision rules may become long and hard to interpret.\n",
    "3. Odor is already a strong predictor in this dataset, so adding more features may not dramatically improve accuracy. However, feel free to experiment with combinations like habitat, ring-type, or population to see if your accuracy or tree simplicity improves.\n",
    "\n",
    "\n",
    "Lastly, print out the rules inferred from your decision tree classifiers when trained over the entire dataset (as opposed to the cross validation trees) with your \"best\" feature subset. Based on the rules, determine ways your trees can/should be pruned. Note you do not need to write code to perform pruning, just explain how they can be pruned and give the resulting \"pruned\" rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS (8 pts)\n",
    "Finish the `visualize_tree()` method of `MyDecisionTreeClassifier` that generates a Graphviz .dot file and a .pdf file. The .dot file is used to produce a visual PDF representation of the decision tree. The tree should have unique nodes for all attributes and leaves in the tree (this means no node should have more than one incoming edge in the visualization). You can read more about dot and how to do this in the [D Tree Visualization and Pruning](https://github.com/DataScienceAlgorithms/M5_DecisionTrees/blob/main/D%20Tree%20Visualization%20and%20Pruning.ipynb) notes on Github. Call this method for the tree fit for part 2 step 2 (e.g. the tree used to print the decision rules). \n",
    "\n",
    "Include the graph generated as a PDF file (produced via dot) in your repo in a directory called `tree_vis`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting Assignments\n",
    "1. Turn in your assignment files via a Github Classroom repo. See the \"Github Classroom Setup\" section at the beginning of this document for details on how to do this.\n",
    "    1. Your repo should contain all of the files needed to run and test your solution (e.g. .py file(s), input files, etc.). \n",
    "    1. Double-check that this is the case by \"pretending to be the grader\": clone (or download a zip) your submission repo and run your code in a fresh [continuumio/anaconda3:2024.06-1](https://hub.docker.com/r/continuumio/anaconda3) Docker container like we will when we grade your code.\n",
    "1. Submit this PA’s associated assignment in Canvas to mark your PA as \"done\" and ready for grading. We will then pull your Github repo and grade your PA as soon as possible. The date and time you submit the PA assignment in Canvas will be used for marking your assignment as \"late\" or \"on-time.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Guidelines\n",
    "This assignment is worth 100 points + 8 points bonus. Your assignment will be evaluated based on a successful execution in the [continuumio/anaconda3:2024.06-1](https://hub.docker.com/r/continuumio/anaconda3) Docker container and adherence to the program requirements. We will grade according to the following criteria:\n",
    "* 20 pts for correct part 1 step 1 (finish iPhone dataset tree and define unit tests)\n",
    "* 25 pts for correct part 1 step 2 (finish `MyDecisionTreeClassifier` and pass `fit()` test)\n",
    "* 10 pts for correct part 1 step 2 (finish `MyDecisionTreeClassifier` and pass `predict()` test)\n",
    "* 10 pts for correct part 1 step 3 (finish `print_decision_rules()`)\n",
    "* 10 pts for correct part 2 (mushroom classification algorithm comparison and evaluation)\n",
    "* 10 pts for correct part 2 (mushroom classification feature subset comparison and evaluation)\n",
    "* 5 pts for correct part 2 (mushroom classification printing of decision rules and pruning commentary)\n",
    "*  10 pts for adherence to course [coding standard](https://github.com/DataScienceAlgorithms/PAs/blob/main/Coding%20Standard.ipynb), including data storytelling (narrative is clear and grammatically correct, Notebook is organized with headers and formulas are typeset with Latex)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
