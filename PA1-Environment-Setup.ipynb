{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CPSC 322]() Data Science Algorithms\n",
    "[Gonzaga University](https://www.gonzaga.edu/) |\n",
    "[Sophina Luitel](https://www.gonzaga.edu/school-of-engineering-applied-science/faculty/detail/sophina-luitel-phd-0dba6a9d)\n",
    "\n",
    "---\n",
    "\n",
    "## PA1 Environment Setup (100 pts)\n",
    "\n",
    "## Learner Objectives\n",
    "At the conclusion of this programming assignment, participants should be able to:\n",
    "* Work with files, functions, and lists in Python\n",
    "* Extract data from a column in a table\n",
    "* Remove missing values\n",
    "* Execute unit tests\n",
    "\n",
    "## Prerequisites\n",
    "Before starting this programming assignment, participants should be able to:\n",
    "* Use variables, operators, conditionals, and loops in Python\n",
    "* Run Python code in Docker containers\n",
    "* Submit assignments via Github Classroom\n",
    "\n",
    "## Acknowledgments\n",
    "Content used in this assignment is based upon information in the following sources:\n",
    "* [Kaggle TV shows dataset](https://www.kaggle.com/ruchi798/tv-shows-on-netflix-prime-video-hulu-and-disney)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github Classroom Setup\n",
    "For this assignment, you will use GitHub Classroom to create a private code repository to track code changes and submit your assignment. Open this PA1 link to accept the assignment and create a private repository for your assignment in Github classroom: https://classroom.github.com/a/Pugg-apj\n",
    "\n",
    "Your repo, for example, will be named DataScienceAlgorithms/pa1-yourusername (where yourusername is your Github username). I highly recommend committing/pushing regularly so your work is always backed up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev Environment Setup (5 pts)\n",
    "Include a screenshot showing your [continuumio/anaconda3:2024.06-1](https://hub.docker.com/r/continuumio/anaconda3) Docker container running locally on your machine. Your screenshot should include your PA1 repository name in some shape or form, for example:\n",
    "\n",
    "![](https://raw.githubusercontent.com/DataScienceAlgorithms/PAs/main/figures/sl_docker_container_running.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming with the üé¨ TV Shows Dataset üé¨ (80 pts)\n",
    "Write a program (`pa1.py`) that opens a data file called [tv_shows.csv](https://www.kaggle.com/ruchi798/tv-shows-on-netflix-prime-video-hulu-and-disney). This file contains \"the data scraped comprises a comprehensive list of tv shows available on various streaming platforms.\" It has the following columns (AKA attributes):\n",
    "1. Unique TV show ID\n",
    "1. Title\n",
    "1. Year: The year in which the tv show was produced\n",
    "1. Age: Target age group\n",
    "1. IMDb: IMDb rating\n",
    "1. Rotten Tomatoes: Rotten Tomatoes %\n",
    "1. Netflix: Whether the tv show is found on Netflix\n",
    "1. Hulu: Whether the tv show is found on Hulu\n",
    "1. Prime Video: Whether the tv show is found on Prime Video\n",
    "1. Disney+: Whether the tv show is found on Disney+\n",
    "\n",
    "Write code to do the following:\n",
    "\n",
    "**1. Load the data**\n",
    "1. Define/call a function that loads the TV shows data into a 2D Python list (AKA table).\n",
    "2.  Remove (and store) the first row, which contains the header of table.\n",
    "3.  You may use Python‚Äôs built-in csv module (recommended), or write the parsing from scratch.\n",
    "    1. Note: you can use the [`csv` module](https://docs.python.org/3/library/csv.html) to help with file I/O if you'd like (but if you want to write it from scratch, see the bonus below!)\n",
    "    \n",
    "**2. Clean the data**\n",
    "\n",
    "2. Finish the function `remove_missing_values(table, header, col_name)`\n",
    "    1. Accepts the following parameters:\n",
    "        1. `table`: the 2D list\n",
    "        1. `header`: the header of the table\n",
    "        1. `col_name`: the name of the column to check for missing values. A missing value is represented as an empty string (\"\"). If a row has a missing value in this column, drop the row.\n",
    "    1. Returns the table with the rows dropped\n",
    "    1. Note: only call this function *per column, as needed*. If you call this function for each column in your table, you are unnecessarily discarding rows that may have usable data in other columns.\n",
    "       \n",
    "**3. Answer the following data science questions (write one function per question):**\n",
    "1. Q1: Which TV show has the highest IMDb rating? \n",
    "    *Note: be sure to use your `remove_missing_values()` function!!*\n",
    "1. Q2: Which streaming service hosts the most TV shows?\n",
    "1. Q3: What is the oldest TV show in the dataset (based on Year)?\n",
    "1. Q4: How many TV shows are rated for the ‚Äú18+‚Äù age group?\n",
    "1. Q5: Define and answer a data science question of your own that you are interested in about the dataset. Be creative!\n",
    "\n",
    "Note: we are learning data science from scratch! The only library you should need to use for this assignment is `csv`. This means you should not `pip install` any additional libraries beyond what is included in the [continuumio/anaconda3:2024.06-1](https://hub.docker.com/r/continuumio/anaconda3) Docker image and no `pandas/numpy/scipy/`etc...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Setup (10 pts)\n",
    "When you have thoroughly tested your code yourself, run the unit test for the `remove_missing_values()` function by running `pytest --verbose test_pa1.py` at the Docker container command line. Once your test passes, include two screenshots:\n",
    "1. (5 pts) The test passing output locally in your terminal\n",
    "1. (5 pts) The test passing output on Github. To see this, push your code, go to your repo on Github, click on the \"Actions\" tab, under \"All workflows\" click your most recent commit, click \"test-code\", and expand \"Test code in Docker container.\" This setup uses Github Actions and is part of a \"continuous integration\" workflow where every time you push your code to Github, a job executes that tests your code. For **reproducible results, this workflow tests your code using the same Docker image you set up to run locally on your machine.** How cool is that!? Congrats, you passed your first unit test running in a Docker container!\n",
    "\n",
    "![](https://raw.githubusercontent.com/DataScienceAlgorithms/PAs/main/figures/sl_pytestlocal.png)\n",
    "\n",
    "![](https://raw.githubusercontent.com/DataScienceAlgorithms/PAs/main/figures/githubtest.png)\n",
    "\n",
    "Note: your screenshots should include your PA1 repository name in some shape or form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting Assignments\n",
    "1. Turn in your assignment files via a Github Classroom repo. See the \"Github Classroom Setup\" section at the beginning of this document for details on how to do this.\n",
    "    1. Your repo should contain all of the files needed to run and test your solution (e.g. .py file(s), input files, etc.). \n",
    "    1. Double-check that this is the case by \"pretending to be the grader\": clone (or download a zip) your submission repo and run your code in a fresh [continuumio/anaconda3:2024.06-1](https://hub.docker.com/r/continuumio/anaconda3) Docker container like we will when we grade your code.\n",
    "1. Submit this PA‚Äôs associated assignment in Canvas to mark your PA as \"done\" and ready for grading. We will then pull your Github repo and grade your PA as soon as possible. The date and time you submit the PA assignment in Canvas will be used for marking your assignment as \"late\" or \"on-time.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Guidelines\n",
    "This assignment is worth 100 points. Your assignment will be evaluated based on a successful execution in the [continuumio/anaconda3:2024.06-1](https://hub.docker.com/r/continuumio/anaconda3) Docker container and adherence to the program requirements. We will grade according to the following criteria:\n",
    "\n",
    "* 5 pts for including a screenshot of your Docker container running locally on your machine\n",
    "* 5 pts loading the table from the csv file\n",
    "* 5 pts for removing missing values\n",
    "* 15 pts for answering Q1\n",
    "* 15 pts for answering Q2\n",
    "* 15 pts for answering Q3\n",
    "* 10 pts for answering Q4\n",
    "* 15 pts for answering Q5\n",
    "* 5 pts for adherence to course [coding standard](https://github.com/DataScienceAlgorithms/PAs/blob/main/Coding%20Standard.ipynb)\n",
    "* 10 pts for passing the unit test and including screenshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
